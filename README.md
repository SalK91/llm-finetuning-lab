# Fine-Tuning GPT-2 for Medical Question Answering using MedQuAD

## ðŸ“– Project Overview
This project aims to fine-tune the GPT-2 model on the MedQuAD (Medical Question-Answer Dataset) to create a domain-specific language model that can accurately answer medical questions. The fine-tuned model will be evaluated using multiple fine-tuning techniques to compare their performance.

### Fine-Tuning Techniques Compared:
1. Vanilla Fine-Tuning: Standard fine-tuning on the MedQuAD dataset.
2. LoRA (Low-Rank Adaptation): Efficient fine-tuning using low-rank adaptation matrices.
3. QLoRA: Combining LoRA with quantized models to reduce memory requirements during fine-tuning.
4. Adapters: Introducing adapter layers to the model for efficient task-specific training.
5. Reinforcement Learning with Human Feedback (RLHF): Fine-tuning the model using human feedback and reward signals.

### Goal:
The goal of this project is to fine-tune GPT-2 to generate accurate medical responses for various medical-related queries. The model's performance will be evaluated on its ability to answer questions from the MedQuAD dataset, and the results from different fine-tuning methods will be compared.

